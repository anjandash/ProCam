{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "video_file = 'drive/MyDrive/video1.mp4'"
      ],
      "metadata": {
        "id": "mA2yJnEUcB52"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import face_recognition\n"
      ],
      "metadata": {
        "id": "nsaS5bU3g_CK"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepface"
      ],
      "metadata": {
        "id": "pXC_qc3KtDWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fer"
      ],
      "metadata": {
        "id": "dJZ1VFXPuUCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fer import FER"
      ],
      "metadata": {
        "id": "lwhH2u7WuWJP"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_detector = FER(mtcnn=True)"
      ],
      "metadata": {
        "id": "IPQ8dr54ubhD"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colour_sad = (51,51,205)\n",
        "colour_happy = (0,255,0)\n",
        "colour_neutral = (77,77,77)\n",
        "dic_color = {'Angry': colour_sad, 'Sad': colour_sad, 'Neutral': colour_neutral,\n",
        "             'Disgust': colour_sad, 'Surprise': colour_happy, 'Fear': colour_sad,\n",
        "             'Happy': colour_happy, 'angry': colour_sad, 'sad': colour_sad, 'neutral': colour_neutral,\n",
        "             'disgust': colour_sad, 'surprise': colour_happy, 'fear': colour_sad,\n",
        "             'happy': colour_happy}"
      ],
      "metadata": {
        "id": "oHttIq-GAa--"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf out-face\n",
        "!mkdir out-face\n",
        "!rm -rf out-faces\n",
        "!mkdir out-faces\n",
        "!rm -rf out\n",
        "!mkdir out"
      ],
      "metadata": {
        "id": "jlwapDAlBaof"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "classifier = load_model(\"drive/MyDrive/model.hdf5\")\n",
        "emotion_dict= {'Angry': 0, 'Sad': 5, 'Neutral': 4, 'Disgust': 1, 'Surprise': 6, 'Fear': 2, 'Happy': 3}\n",
        "label_map = dict((v,k) for k,v in emotion_dict.items()) \n",
        "\n",
        "vidcap = cv2.VideoCapture(video_file)\n",
        "success,img = vidcap.read()\n",
        "\n",
        "count = 0\n",
        "dict_emotions = {}\n",
        "while success:\n",
        "  cv2.imwrite(\"out/frame%d.jpg\" % count, img)\n",
        "\n",
        "  face_locations = face_recognition.face_locations(img)\n",
        "  if len(face_locations)>0:\n",
        "    for each_face in face_locations:\n",
        "      top, right, bottom, left = each_face\n",
        "      face_image = img[top:bottom, left:right]\n",
        "      dominant_emotion, emotion_score = emotion_detector.top_emotion(face_image)\n",
        "      dict_emotions[count] = {'dominant_emotion': dominant_emotion, 'emotion_score': emotion_score}\n",
        "\n",
        "      cv2.imwrite(\"out-face/frame%d.jpg\" % count, face_image) \n",
        "      if dominant_emotion is not None:\n",
        "        cv2.rectangle(img, (left, top), (right, bottom), dic_color[dominant_emotion], 2)\n",
        "        cv2.putText(img, dominant_emotion, (left, top-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n",
        "                    dic_color[dominant_emotion], 2)\n",
        "      else:\n",
        "        cv2.rectangle(img, (left, top), (right, bottom), colour_neutral, 2)\n",
        "\n",
        "    cv2.imwrite(\"out-faces/frame%d.jpg\" % count, img) \n",
        "  success,img = vidcap.read()\n",
        "  count += 1\n"
      ],
      "metadata": {
        "id": "ciA7Eq0IeCFS"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as path\n",
        "import os\n",
        "\n",
        "image_folder = 'out-faces'\n",
        "\n",
        "\n",
        "frame = cv2.imread(os.path.join('out', 'frame100.jpg'))\n",
        "height, width, layers = frame.shape\n",
        "size = (width, height)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
        "video = cv2.VideoWriter('output.mp4', fourcc, 30, (width,height))\n",
        "\n",
        "for i in range(450):\n",
        "  if path.exists(os.path.join('out-faces', 'frame' + str(i) + '.jpg')):\n",
        "    video.write(cv2.imread(os.path.join('out-faces', 'frame' + str(i) + '.jpg')))\n",
        "  else:\n",
        "    video.write(cv2.imread(os.path.join('out', 'frame' + str(i) + '.jpg')))\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ],
      "metadata": {
        "id": "_cH82HKMzhBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guh4uItG7Ihz",
        "outputId": "3066ae29-a3e0-4de9-c211-36738702f728"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive\t\t\t\t     out       out-faces    sample_data\n",
            "haarcascade_frontalface_default.xml  out-face  project.avi\n"
          ]
        }
      ]
    }
  ]
}